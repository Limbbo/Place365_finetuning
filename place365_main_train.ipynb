{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import temp\n",
    "import torch.nn as nn\n",
    "import torchvision.models as model\n",
    "from torchvision import transforms as trn\n",
    "import os\n",
    "import sys\n",
    "from PIL import Image\n",
    "from torch.autograd import Variable as V\n",
    "import torchvision.models as models\n",
    "from torch.nn import functional as F\n",
    "import torch.optim as optim\n",
    "from sklearn.svm import SVC\n",
    "from torch.utils.data import DataLoader\n",
    "from copy import deepcopy\n",
    "from torch.autograd import Variable\n",
    "from torchvision import datasets, models, transforms\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn.utils import shuffle\n",
    "import numpy as np\n",
    "\n",
    "mean = [0.4856586910840433, 0.4856586910840433, 0.4856586910840433]\n",
    "std = [0.14210993338737993, 0.14210993338737993, 0.14210993338737993]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.RandomSizedCrop(220),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean, std)\n",
    "    ]),\n",
    "    'validation': transforms.Compose([\n",
    "        transforms.Scale(224),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean, std)\n",
    "    ]),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "model = model.cuda()\n",
    "model.eval()\n",
    "\n",
    "model = torch.nn.DataParallel(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BYNET(nn.Module):\n",
    "    def __init__(self, num_classes=15):\n",
    "        super(BYNET, self).__init__()\n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Conv2d(512, 512, kernel_size=(14,14), stride=(14,14))\n",
    "        )\n",
    "        self.layer_relu = nn.Sequential(\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512*4, 1024)\n",
    "        )\n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Conv2d(1024, 1024, kernel_size=(7, 7), stride=(7,7))\n",
    "        )\n",
    "        self.layer2_relu = nn.Sequential(\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(1024*4, 1024)\n",
    "        )\n",
    "        self.layer3 = nn.Sequential(\n",
    "            nn.Conv2d(2048, 2048, kernel_size=(4, 4), stride=(3,3))          \n",
    "        )\n",
    "        self.layer3_relu = nn.Sequential(\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(2048*4, 1024)\n",
    "        )\n",
    "        \n",
    "        self.fc1 = nn.Linear(1024*3,1024)\n",
    "        self.fc2 = nn.Linear(1024, 395)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out1 = self.layer1(x[0])\n",
    "        out1 = out1.view(-1, num_flat_features(out1))\n",
    "        out1 = self.layer_relu(out1) \n",
    "        \n",
    "        out2 = self.layer2(x[1])\n",
    "        out2 = out2.view(-1, num_flat_features(out2))\n",
    "        out2 = self.layer2_relu(out2) \n",
    "        \n",
    "        out3 = self.layer3(x[2])\n",
    "        out3 = out3.view(-1, num_flat_features(out3))\n",
    "        out3 = self.layer3_relu(out3) \n",
    "        \n",
    "        out = torch.cat((out1,out2,out3),1)\n",
    "        out = self.fc1(out)\n",
    "        out = self.fc2(out)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def num_flat_features(x):\n",
    "        size = x.size()[1:]  # all dimensions except the batch dimension\n",
    "        num_features = 1\n",
    "        for s in size:\n",
    "            num_features *= s\n",
    "        return num_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model_ft,optimizer,scheduler,net,num_epochs):\n",
    "    \n",
    "    best_model_wts = deepcopy(net.state_dict())\n",
    "    best_acc = 0.0\n",
    "        \n",
    "    for epoch in range(1,num_epochs+1):\n",
    "        for phase in ['train','validation']:\n",
    "            if phase == 'train':\n",
    "                scheduler.step()\n",
    "                print('\\n=> Training Epoch #%d' %(epoch))\n",
    "                net.train()\n",
    "            else:\n",
    "                print('\\n=> Validation Epoch #%d' %(epoch))\n",
    "                net.eval()\n",
    "\n",
    "            running_loss = 0.0       \n",
    "            running_corrects = 0\n",
    "            tot = 0.0\n",
    "\n",
    "            for batch_idx, (inputs, target) in enumerate(dset_loaders[phase]):\n",
    "                inputs, target = Variable(inputs.cuda()), Variable(target.cuda())\n",
    "\n",
    "                #추가된 layer 이외에 다른 layer는 학습 x\n",
    "                for param in model.parameters():\n",
    "                    param.requires_grad = False\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "\n",
    "                out1 = model_ft.module.conv1.forward(inputs)\n",
    "                out2 = model_ft.module.relu(model_ft.module.bn1(out1))\n",
    "                out3 = model_ft.module.maxpool.forward(out2)\n",
    "\n",
    "                layer1_feature = model_ft.module.layer1.forward(out3)\n",
    "                layer2_feature = model_ft.module.layer2.forward(layer1_feature)\n",
    "                layer3_feature = model_ft.module.layer3.forward(layer2_feature)\n",
    "                layer4_feature = model_ft.module.layer4.forward(layer3_feature)\n",
    "\n",
    "                layer_feature_list = list()\n",
    "                layer_feature_list.append(layer2_feature)\n",
    "                layer_feature_list.append(layer3_feature)\n",
    "                layer_feature_list.append(layer4_feature)\n",
    "\n",
    "                output = net.forward(layer_feature_list)    \n",
    "                _,preds = torch.max(output.data,1)\n",
    "                loss  = criterion(output, target)\n",
    "                \n",
    "                if phase == 'train':\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "\n",
    "                running_loss += loss.item()\n",
    "                running_corrects += preds.eq(target.data).cpu().sum()\n",
    "                tot += target.size(0)\n",
    "\n",
    "                if phase == 'train':\n",
    "                    sys.stdout.write('\\r')\n",
    "                    sys.stdout.write('| Epoch [%2d/%2d] Iter [%3d/%3d]\\t\\tLoss %.4f\\tAcc %.2f%%'\n",
    "                            %(epoch, num_epochs, batch_idx,\n",
    "                                (len(dsets[phase])//190)+1, loss.data[0], 100.*running_corrects/tot))\n",
    "                    sys.stdout.flush()\n",
    "                    sys.stdout.write('\\r')\n",
    "                if phase == 'validation':\n",
    "                    print(\"===> Validation Epoch[{}]({}/{}): Loss: {:.4f}: Accuracy: {:.4f}\".format(epoch, batch_idx, dset_sizes['validation'], loss.data[0],100.*running_corrects/tot))\n",
    "\n",
    "            epoch_loss = running_loss / dataset_sizes[phase]\n",
    "            epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
    "            \n",
    "            if phase == 'validation' and epoch_acc > best_acc:\n",
    "                print('\\n| Validation Epoch #%d\\t\\t\\tLoss %.4f\\tAcc %.2f%%'\n",
    "                    %(epoch, loss.data[0], 100.*epoch_acc))\n",
    "                best_acc = epoch_acc\n",
    "                best_model_wts = deepcopy(net.state_dict())\n",
    "\n",
    "                if not os.path.isdir('checkpoint'):\n",
    "                    os.mkdir('checkpoint')\n",
    "                save_point = './checkpoint/'\n",
    "                if not os.path.isdir(save_point):\n",
    "                    os.mkdir(save_point)\n",
    "                torch.save(best_model_wts, '{}.pth'.format('BYNET_best_sun397'))\n",
    "        \n",
    "        net_copy = deepcopy(net.state_dict())\n",
    "        torch.save(net, '{}.pth'.format(epoch))\n",
    "        \n",
    "    print('Best validation Acc\\t{:.2f}%'.format(best_acc*100))\n",
    "    \n",
    "    return best_model_wts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "net = BYNET().cuda()\n",
    "optimizer = torch.optim.SGD(net.parameters(), lr=0.1,weight_decay=1e-2)\n",
    "scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer,milestones=learning_milestones,gamma=0.8)\n",
    "net_ft = train_model(model, optimizer,scheduler,net,100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
